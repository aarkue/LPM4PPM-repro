{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "reported_data = {}\n",
    "def populate_reported_data():\n",
    "    all_values = [74.76, 69.06, 69.07, 81.38, 72.66, 72.70, 78.77, 70.52, 70.55, 84.58, 75.05, 75.05, 84.71, 76.36, 76.38, 67.62, 63.77, 62.51, 80.21, 79.06, 77.01, 81.48, 79.42, 77.83, 77.71, 77.87, 75.71, 89.51, 85.55, 84.69, 89.85, 85.05, 84.14, 47.20, 70.10, 57.78, 74.43, 72.64, 70.93, 76.18, 73.52, 73.81, 74.65, 72.75, 69.37, 79.95, 74.97, 75.16, 81.58, 76.08, 73.85, 71.28, 71.72, 63.40, 72.27, 63.31, 63.55, 73.72, 65.49, 65.67, 73.18, 65.17, 64.64, 78.04, 68.97, 69.10, 79.34, 69.87, 69.93, 69.22, 64.60, 63.50, 69.83, 63.11, 62.49, 70.07, 63.35, 62.49, 70.11, 63.49, 62.85, 71.00, 63.00, 60.78, 72.09, 64.35, 63.73, 65.65, 59.99, 58.80, 63.15, 83.88, 77.26, 66.20, 83.90, 77.32, 66.09, 83.97, 77.56, 64.2, 84.01, 77.67, 66.65, 84.00, 77.65, 64.62, 82.90, 75.60, 70.73, 71.66, 66.24, 76.90, 75.76, 72.46, 76.81, 74.92, 72.02, 71.35, 71.87, 65.53, 77.42, 75.55, 71.78, 72.44, 74.00, 70.02, 61.69, 55.64, 53.48, 62.49, 56.79, 54.37, 61.87, 54.85, 51.54, 78.80, 72.51, 72.20, 79.12, 72.75, 72.54, 64.27, 53.53, 37.33, 81.98, 80.94, 80.10, 81.95, 80.95, 80.10, 81.97, 80.95, 80.10, 82.17, 81.28, 80.52, 82.13, 81.29, 80.54, 68.18, 64.49, 58.59]\n",
    "    datasets = [\"BPIC2011-f1\",\"BPIC2011-f2\",\"BPIC2011-f3\",\"BPIC2011-f4\",\"BPIC2012-ac\",\"BPIC2012-re\",\"BPIC2012-ca\",\"Production\",\"Traffic Fine\"]\n",
    "    encodings = [\"OH_ACT\",\"WOH_BIN\",\"WOH_FREQ\",\"EMB_ACT\",\"EMB_ACT+LPM\",\"EMB_LPM\"]\n",
    "    metrics = [\"roc-auc\",\"accuracy\",\"w_f1\"]\n",
    "    print(len(all_values))\n",
    "    for i in range(len(all_values)):\n",
    "        dataset_index = max([0,math.floor(i/(len(metrics)*len(encodings)))])\n",
    "        d = datasets[dataset_index]\n",
    "        e = encodings[math.floor(i/len(metrics))%len(encodings)]\n",
    "        m = metrics[i%len(metrics)]\n",
    "        print(d,e,m,\": \", all_values[i])\n",
    "        reported_data[(d,e,m)] = all_values[i]/100.0\n",
    "populate_reported_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import glob\n",
    "import subprocess\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "main_data_folder = \"../data/main\"\n",
    "alternative_data_folder = \"../data/imf-alternative\"\n",
    "figure_path = \"../figures/\"\n",
    "plt.rc('font', size=16)\n",
    "logs = {\n",
    "    \"BPIC11_f1\": \"BPIC2011-f1\",\n",
    "    \"BPIC11_f2\": \"BPIC2011-f2\",\n",
    "    \"BPIC11_f3\": \"BPIC2011-f3\",\n",
    "    \"BPIC11_f4\": \"BPIC2011-f4\",\n",
    "    \"Production\": \"Production\",\n",
    "    \"traffic_fines_1\": \"Traffic Fine\",\n",
    "        }\n",
    "all_results = {}\n",
    "alt_all_results = {}\n",
    "for log_name in logs:\n",
    "    filename = f\"{main_data_folder}/results/{log_name}/\"\n",
    "    alt_filename = f\"{main_data_folder}/results/{log_name}/\"\n",
    "    all_results[log_name] = dict()\n",
    "    alt_all_results[log_name] = dict()\n",
    "    for file in glob.glob(filename + \"*_info.json\"):\n",
    "        mode = \"_\".join(file.split(\"/\")[-1].split(\"_\")[-3:-1])\n",
    "        with open(file, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            mode_data = all_results[log_name].get(mode,[])\n",
    "            mode_data.append(json_data)\n",
    "            all_results[log_name][mode] = mode_data\n",
    "    for file in glob.glob(alt_filename + \"*_info.json\"):\n",
    "        mode = \"_\".join(file.split(\"/\")[-1].split(\"_\")[-3:-1])\n",
    "        with open(file, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            mode_data = alt_all_results[log_name].get(mode,[])\n",
    "            mode_data.append(json_data)\n",
    "            alt_all_results[log_name][mode] = mode_data\n",
    "    print(all_results[log_name].keys())\n",
    "    measure_labels = {\"roc-auc\": \"AUC\", \"accuracy\": \"Accuracy\", \"w_f1\": \"F1-score\"} \n",
    "encodings = {\"OH_ACT\": \"$OH_{Act}$\",\"WOH_BIN\": \"$WOH_{Bin}$\",\"WOH_FREQ\": \"$WOH_{Freq}$\",\"EMB_ACT\": \"$Emb_{Act}$\",\"EMB_ACT+LPM\": \"$Emb_{Act+LPMs}$\",\"EMB_LPM\": \"$Emb_{LPMs}$\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "time_stamp = datetime.datetime.now().isoformat()\n",
    "\n",
    "def format_and_round(value):\n",
    "    return \"{:2.2f}\".format(value) + \"\\%\"\n",
    "\n",
    "conf_fact = 3\n",
    "\n",
    "with open(\n",
    "        f\"../table-data_{time_stamp}.csv\",\n",
    "        \"w\",\n",
    "        newline=\"\",\n",
    "    ) as f:\n",
    "        w = csv.writer(f)\n",
    "        for log_name in logs:\n",
    "            long_log_name = logs[log_name]\n",
    "            for enc in encodings:\n",
    "                row = []\n",
    "                for measure in measure_labels:\n",
    "                    values = [v['test_res'][measure] for v in all_results[log_name][enc]]\n",
    "                    values = [v for v in values if v != 0.0]\n",
    "                    reported_value = reported_data[(long_log_name,enc,measure)]\n",
    "                    sd = np.std(values)\n",
    "                    mean = np.mean(values)\n",
    "                    interesting = 'no'\n",
    "                    print(mean,mean-conf_fact * sd,reported_value)\n",
    "                    if reported_value >= mean - conf_fact * sd and reported_value <= mean + conf_fact * sd:\n",
    "                         pass\n",
    "                    elif reported_value >= mean - conf_fact * sd:\n",
    "                        interesting = 'above'\n",
    "                    else:\n",
    "                        interesting = 'below'\n",
    "                    maxi = np.max(values)\n",
    "                    median = np.median(values)\n",
    "                    formatted_reported = format_and_round(reported_value*100.0)\n",
    "                    if interesting == 'above':\n",
    "                         formatted_reported = f\"\\\\textbf{{{formatted_reported}}}\"\n",
    "                    row.append(formatted_reported)\n",
    "                    row.append(format_and_round(maxi*100.0))\n",
    "                    formatted_mean = format_and_round(mean*100.0)\n",
    "                    if interesting == 'below':\n",
    "                         print(\"!\")\n",
    "                         formatted_mean = f\"\\\\textbf{{{formatted_mean}}}\"\n",
    "                    row.append(formatted_mean)\n",
    "                    row.append(format_and_round(median*100.0))\n",
    "                    row.append(format_and_round(sd*100.0))\n",
    "                w.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "in_confidence_interval = 0\n",
    "higher_than_conf_int = 0\n",
    "lower_than_conf_int = 0\n",
    "confidence_interval_factor = 3\n",
    "mode_confidence_data = {}\n",
    "for mode in encodings:\n",
    "    mode_confidence_data[mode] = {\n",
    "        \"in\": 0,\n",
    "        \"higher\": 0,\n",
    "        \"lower\": 0\n",
    "    }\n",
    "alt_mode_confidence_data = {}\n",
    "for mode in encodings:\n",
    "    alt_mode_confidence_data[mode] = {\n",
    "        \"in\": 0,\n",
    "        \"higher\": 0,\n",
    "        \"lower\": 0\n",
    "    }\n",
    "confidence_interval_percentage = \"$>68\\%$\" if confidence_interval_factor == 1 else (\"$>95\\%$\" if confidence_interval_factor == 2 else (\"$>99\\%$\" if confidence_interval_factor >= 3 else \"??\"))\n",
    "for log_name in logs:\n",
    "    full_log_name = logs[log_name]\n",
    "    for mode in all_results[log_name]:\n",
    "        for measure in measure_labels:\n",
    "            print(measure + \" for \" + mode)\n",
    "            raw_values = [v['test_res'][measure] for v in all_results[log_name][mode]]\n",
    "            filtered_values = [v for v in raw_values if v != 0]\n",
    "            mean = np.mean(filtered_values)\n",
    "            std = np.std(filtered_values)\n",
    "\n",
    "            # raw_values_alt = [v['test_res'][measure] for v in alt_all_results[log_name][mode]]\n",
    "            # for v in raw_values_alt:\n",
    "            #     if v >= mean - confidence_interval_factor * std and v <= mean + confidence_interval_factor * std:\n",
    "            #         alt_mode_confidence_data[mode][\"in\"] += 1\n",
    "            #     elif v >= mean - confidence_interval_factor * std:\n",
    "            #         alt_mode_confidence_data[mode][\"higher\"] += 1\n",
    "            #     else:\n",
    "            #         alt_mode_confidence_data[mode][\"lower\"] += 1\n",
    "            # filtered_values_alt = [v for v in raw_values if v != 0]\n",
    "            reported_value = reported_data[(full_log_name,mode,measure)]\n",
    "            if reported_value >= mean - confidence_interval_factor * std and reported_value <= mean + confidence_interval_factor * std:\n",
    "                in_confidence_interval += 1\n",
    "                mode_confidence_data[mode][\"in\"] += 1\n",
    "            elif reported_value >= mean - confidence_interval_factor * std:\n",
    "                higher_than_conf_int += 1\n",
    "                mode_confidence_data[mode][\"higher\"] += 1\n",
    "            else:\n",
    "                lower_than_conf_int += 1\n",
    "                mode_confidence_data[mode][\"lower\"] += 1\n",
    "            sns.boxplot(filtered_values, orient=\"h\",color=\"#ccdafc50\", whis=99999999)\n",
    "            plt.scatter(raw_values,[0 for acc in raw_values],label=\"measured values\", alpha=0.8)\n",
    "            plt.scatter([mean],[0],label=\"measured mean ($\\mu$)\", alpha=0.8, marker=\"+\", sizes=[100], color=\"green\")\n",
    "            # plt.scatter(raw_values_alt,[0 for acc in raw_values],label=\"measured values\\n(alternative LPM discovery)\", alpha=0.8, color=\"red\")\n",
    "            plt.scatter([reported_value],[0],label=\"reported value\", alpha=0.8)\n",
    "            ax = plt.gca()\n",
    "            f = plt.gcf()\n",
    "            f.set_figwidth(15)\n",
    "            f.set_figheight(2.5)\n",
    "            r_width = std * 2 * confidence_interval_factor\n",
    "            r_height = 0.25\n",
    "            ax.add_patch(plt.Rectangle((mean - r_width/2,-r_height/2),r_width,r_height, alpha=0.3, label=f\"$\\mu \\pm {confidence_interval_factor}\\sigma$ ({confidence_interval_percentage} for ND)\", color=\"pink\"))\n",
    "            ax.legend(loc=(1.01, 0.2))\n",
    "            ax.set_title(f\"{measure_labels[measure]} for {full_log_name} with encoding {encodings[mode]}\")\n",
    "            ax.set_xlim([0.0,1.0])\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            svg_path = f\"{figure_path}/{measure} for {full_log_name} with encoding {mode}_error.pdf\"\n",
    "            plt.savefig(svg_path, bbox_inches='tight')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_confidence_interval,lower_than_conf_int,higher_than_conf_int)\n",
    "print(in_confidence_interval/(in_confidence_interval + lower_than_conf_int + higher_than_conf_int))\n",
    "for m in encodings:\n",
    "    print(m,mode_confidence_data[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in encodings:\n",
    "    print(m,alt_mode_confidence_data[m])\n",
    "better_interval_dir_names = {\"in\": \"similar\",\"higher\":\"better\", \"lower\":\"worse\"}\n",
    "alt_confidence_df = pd.DataFrame([(encodings[m],better_interval_dir_names[direction],alt_mode_confidence_data[m][direction]) for m in encodings for direction in alt_mode_confidence_data[m]],columns=[\"Encoding\",\"Performance\",\"Count\"])\n",
    "alt_confidence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.barplot(alt_confidence_df,x=\"Encoding\",y=\"Count\", hue=\"Performance\", hue_order=[\"worse\",\"similar\",\"better\"],palette = {\n",
    "    'similar': 'tab:blue',\n",
    "    'better': 'tab:green',\n",
    "    'worse': 'tab:orange',\n",
    "}\n",
    ")\n",
    "ax.set_ylabel(\"Number of values\\n(across all metrics)\")\n",
    "ax.set_title(\"Performance of alternative approach compared to original\")\n",
    "sns.move_legend(ax,loc=(1.01, 0.6 ))\n",
    "plt.savefig(\"{figure_path}/performance-comparison-alt-approach.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "values = []\n",
    "for log_name in logs:\n",
    "    for m in encodings:\n",
    "        for d in all_results[log_name][m]:\n",
    "            values.append({\"log_name\": log_name,\"Encoding\": encodings[m],**d['test_res'],**d['parameters']})\n",
    "df = pd.DataFrame(values)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = [d['parameters']  for log_name in logs for m in encodings for d in all_results[log_name][m]]\n",
    "hps_per_mode = {m: d['parameters'] for m in encodings for log_name in logs  for d in all_results[log_name][m]}\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_palette(\"pastel\")\n",
    "sns.histplot(df,alpha=1.0, discrete=True, shrink=.8, hue=\"Encoding\", x=\"layers\", multiple='stack', legend=None)\n",
    "ax = plt.gca()\n",
    "# sns.move_legend(ax,loc=(1.01, 0.2))\n",
    "ax.set_title(\"Number of layers\")\n",
    "ax.set_xlabel(\"Number of layers\")\n",
    "# ax.set_xticks([1,2,3,4])\n",
    "# ax.set_yticks([i for i in range(0,22,2)])\n",
    "# ax.set_xlim([0,5])\n",
    "plt.savefig(f\"{figure_path}/layer-sizes.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df,alpha=1.0, discrete=True, shrink=.8, hue=\"Encoding\", x=\"activation\", multiple='stack')\n",
    "ax = plt.gca()\n",
    "sns.move_legend(ax,loc=(1.01, 0.2))\n",
    "ax.set_title(\"Activation functions\")\n",
    "ax.set_xlabel(\"Activation functions\")\n",
    "plt.savefig(f\"{figure_path}/activation-funs.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df,alpha=1.0, hue=\"Encoding\", x=\"learning_rate\", multiple='stack',log_scale=True)\n",
    "plt.gcf().set_figwidth(15)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Learning rate\")\n",
    "ax.set_xlabel(\"Learning rate\")\n",
    "plt.savefig(f\"{figure_path}/learning-rate.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(df,alpha=1.0, binwidth=30, hue=\"Encoding\", x=\"units_0\", multiple='stack')\n",
    "ax = plt.gca()\n",
    "sns.move_legend(ax,loc=(1.01, 0.2))\n",
    "ax.set_title(\"Units in first layer\")\n",
    "ax.set_xlabel(\"Units in first layer\")\n",
    "plt.savefig(f\"{figure_path}/units-in-layer-0_per_encoding.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.histplot([h['units_0'] for h in hps], kde=True, alpha=1.0, binwidth=15)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Units in first layer\")\n",
    "ax.set_xlabel(\"Units in first layer\")\n",
    "plt.savefig(f\"{figure_path}/units-in-layer-0.pdf\",bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot([h['dropoutrate_0'] for h in hps], kde=True, alpha=1.0, binwidth=0.1)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Dropout rate in first layer\")\n",
    "ax.set_xlabel(\"Dropout rate in first layer\")\n",
    "plt.savefig(f\"{figure_path}/dropout-in-layer-0.pdf\",bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_with_two_layers = [p for p in hps if p['layers'] >= 2]\n",
    "sns.histplot([h['units_1'] for h in hps_with_two_layers], kde=True, alpha=1.0, binwidth=15)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Units in second layer\")\n",
    "plt.savefig(f\"{figure_path}/units-in-layer-1_{log_name}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "sns.histplot([h['dropoutrate_1'] for h in hps_with_two_layers], kde=True, alpha=1.0, binwidth=0.1)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Dropout rate in second layer\")\n",
    "plt.savefig(f\"{figure_path}/dropout-in-layer-1_{log_name}.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
